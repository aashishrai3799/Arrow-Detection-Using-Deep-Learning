{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "arroy_detect_Copy1_(1) (2).ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzlyU5nrvpWp",
        "colab_type": "text"
      },
      "source": [
        "## **Arrow Detection with Direction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLjAfhqxxOPq",
        "colab_type": "text"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mXfHdocv7pq7",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPool2D,  \\\n",
        "    Dropout, Dense, Input, concatenate,      \\\n",
        "    GlobalAveragePooling2D, AveragePooling2D,\\\n",
        "    Flatten, Conv2DTranspose\n",
        "\n",
        "import cv2 \n",
        "import numpy as np \n",
        "from keras.datasets import cifar10 \n",
        "from keras import backend as K \n",
        "from keras.utils import np_utils\n",
        "\n",
        "import math \n",
        "from keras.optimizers import SGD \n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCoadQb4xgu7",
        "colab_type": "text"
      },
      "source": [
        "Generate & Save Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R7xmA4Dz7prD",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Drive1(Own)/Arrow224/train/'\n",
        "classes = os.listdir(path)\n",
        "train_size = 704\n",
        "file_size = 160\n",
        "print(classes)\n",
        "index = 0\n",
        "counter = 0\n",
        "X_train = np.zeros((train_size, int(file_size), int(file_size), 3), dtype = 'uint8')\n",
        "Y_train = np.zeros((train_size), dtype = 'uint8')\n",
        "\n",
        "for i in classes:\n",
        "\n",
        "    print('class: ', i)\n",
        "    files = os.listdir(str(path) + str(i))\n",
        "\n",
        "    for k in files:\n",
        "        img = Image.open(str(path) + str(i) + '/' + str(k))\n",
        "        img.load\n",
        "        img = img.resize((int(file_size), int(file_size)), Image.ANTIALIAS)\n",
        "        npimg = np.asarray( img, dtype=\"uint8\" )\n",
        "        X_train[counter,:,:,:] = npimg\n",
        "        Y_train[counter] = classes.index(i)\n",
        "        counter += 1\n",
        "    \n",
        "print(counter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y9lDN5J_7prQ",
        "colab": {}
      },
      "source": [
        "train_size = 704\n",
        "#test_size = 70\n",
        "\n",
        "train_images = np.resize(X_train, (train_size, 160, 160, 3)) / 255\n",
        "train_labels = np.resize(Y_train, (train_size))\n",
        "\n",
        "#test_images = np.resize(X_train, (test_size, 160, 160, 3)) / 255\n",
        "#test_labels = np.resize(Y_test, (test_size))\n",
        "\n",
        "print(train_images.shape, train_labels.shape)\n",
        "#print(test_images.shape, test_labels.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eObs1ZkFyjUF",
        "colab_type": "text"
      },
      "source": [
        "Define Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlLUP1wf-bPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_size = 16\n",
        "x = keras.layers.Input(shape=(160, 160, 3))\n",
        "\n",
        "gen1 = keras.layers.Conv2D(8, (4, 4), padding = 'SAME', activation = 'relu')(x)\n",
        "P1 = keras.layers.MaxPooling2D(2, padding = 'SAME')(gen1)\n",
        "\n",
        "gen2 = keras.layers.Conv2D(16, (4, 4), padding = 'SAME', activation = 'relu')(P1)\n",
        "P2 = keras.layers.MaxPooling2D(4, padding = 'SAME')(gen2)\n",
        "\n",
        "gen3 = keras.layers.Conv2D(32, (4, 4), padding = 'SAME', activation = 'relu')(P2)\n",
        "P3 = keras.layers.MaxPooling2D(2, padding = 'SAME')(gen3)\n",
        "\n",
        "gen4 = keras.layers.Conv2D(16, (4, 4), padding = 'SAME', activation = 'relu')(P3)\n",
        "P4 = keras.layers.MaxPooling2D(4, padding = 'SAME')(gen4)\n",
        "\n",
        "gen4 = keras.layers.Conv2D(8, (4, 4), padding = 'SAME', activation = 'sigmoid')(P4)\n",
        "P4 = keras.layers.MaxPooling2D(2, padding = 'SAME')(gen4)\n",
        "\n",
        "x4 = keras.layers.Flatten()(P4)\n",
        "x5 = keras.layers.Dense(3, activation = 'softmax')(x4)\n",
        "\n",
        "model = keras.models.Model([x], x5)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY7g0pqHymcr",
        "colab_type": "text"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MKuil1T87prZ",
        "colab": {}
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=15, batch_size = 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMMWheM3yo_i",
        "colab_type": "text"
      },
      "source": [
        "Save Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WhK040Gj7prf",
        "colab": {}
      },
      "source": [
        "model.save_weights('/content/sui_arrow.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jzFIS9Oyr2p",
        "colab_type": "text"
      },
      "source": [
        "Test random images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KiEe3OqQ7prj",
        "colab": {}
      },
      "source": [
        "img = Image.open('/content/drive/My Drive/Drive1(Own)/Arrow224/test/right/Untitled16.jpg')\n",
        "img.load\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "img = img.resize((160, 160), Image.ANTIALIAS)\n",
        "npimg = np.asarray(img, dtype=\"uint8\" )\n",
        "print('shape', np.shape(npimg))\n",
        "test_image = np.resize(npimg, (1, 160, 160, 3))\n",
        "print('shape', np.shape(test_image))\n",
        "predictions = model.predict(test_image)\n",
        "print(predictions)\n",
        "classes = ['L', 'R', 'N']\n",
        "print(classes[np.argmax(predictions)])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}